# ü§ñ JIRA AI Classifier - Gu√≠a de Setup

Sistema completo para clasificar autom√°ticamente tickets de JIRA usando IA local con Gemma 8B.

## üìã Requisitos Previos

- Python 3.8 o superior
- Acceso a una instancia de JIRA con API token
- Al menos 8GB de RAM disponible para el modelo Gemma

## üöÄ Instalaci√≥n Paso a Paso

### 1. Instalar Ollama

**Ubuntu/Debian:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**macOS:**
```bash
brew install ollama
```

**Windows:**
Descarga el instalador desde: https://ollama.ai/download

### 2. Descargar el modelo Gemma 8B

```bash
# Iniciar Ollama (si no se inici√≥ autom√°ticamente)
ollama serve

# En otra terminal, descargar Gemma 8B
ollama pull gemma:8b
```

**Nota:** La descarga del modelo puede tomar varios minutos (aproximadamente 5GB).

### 3. Configurar el proyecto Python

```bash
# Instalar dependencias
pip install -r requirements.txt

# Copiar archivo de configuraci√≥n
cp .env.example .env
```

### 4. Configurar credenciales de JIRA

Edita el archivo `.env` con tus credenciales:

```bash
# Abre el archivo .env en tu editor favorito
nano .env
```

Completa los siguientes valores:

```env
JIRA_SERVER=https://tucompania.atlassian.net
JIRA_EMAIL=tu-email@empresa.com
JIRA_API_TOKEN=tu_api_token_de_jira
JIRA_PROJECT_KEY=PROJ  # Opcional: clave de tu proyecto
```

#### üîë ¬øC√≥mo obtener tu JIRA API Token?

1. Ve a: https://id.atlassian.com/manage-profile/security/api-tokens
2. Haz clic en "Create API token"
3. Dale un nombre descriptivo (ej: "JIRA AI Classifier")
4. Copia el token generado (gu√°rdalo en lugar seguro)

## üß™ Verificar la Instalaci√≥n

### Verificar Ollama y Gemma:
```bash
# Verificar que Ollama est√© funcionando
curl http://localhost:11434/api/version

# Probar el modelo Gemma
ollama run gemma:7b "Hola, ¬øc√≥mo est√°s?"
```

### Verificar conexi√≥n con JIRA:
```bash
# Ejecutar el clasificador en modo test
python main.py
```

## üìö Uso del Sistema

### 1. Crear tickets de prueba (opcional)

```bash
# Ejecutar el seeder para crear 25 tickets de ejemplo
python seeder.py
```

### 2. Ejecutar el clasificador

```bash
# Clasificar tickets
python main.py
```

El sistema te dar√° 3 opciones:
1. **Clasificar tickets actualizados hoy** - Procesa solo tickets modificados hoy
2. **Clasificar TODOS los tickets** - Procesa todos los tickets del proyecto
3. **Solo analizar** - Muestra las clasificaciones sin aplicar cambios

### 3. Opciones adicionales

```bash
# Mostrar ayuda
python main.py --help

# Mostrar versi√≥n
python main.py --version
```

## üè∑Ô∏è Categor√≠as de Clasificaci√≥n

El sistema clasifica tickets en las siguientes categor√≠as:

- **mantenimiento** - Tareas de mantenimiento y correcciones menores
- **soporte** - Tickets de soporte t√©cnico y ayuda al usuario
- **iniciativa** - Nuevas funcionalidades e iniciativas de negocio
- **bug** - Errores y fallos del sistema
- **optimizacion** - Mejoras de rendimiento y optimizaciones
- **documentacion** - Creaci√≥n y actualizaci√≥n de documentaci√≥n
- **infraestructura** - Cambios en infraestructura y DevOps
- **seguridad** - Vulnerabilidades y mejoras de seguridad

## üõ†Ô∏è Comandos de Desarrollo

### Reiniciar Ollama:
```bash
# Detener Ollama
pkill ollama

# Iniciar Ollama
ollama serve
```

### Ver logs de Ollama:
```bash
# En macOS/Linux
tail -f ~/.ollama/logs/server.log
```

### Verificar modelos instalados:
```bash
ollama list
```

## üîß Soluci√≥n de Problemas

### ‚ùå Error: "No se puede conectar con Ollama"

**Soluci√≥n:**
```bash
# Verificar que Ollama est√© ejecut√°ndose
ps aux | grep ollama

# Si no est√° ejecut√°ndose:
ollama serve

# Verificar el puerto:
netstat -an | grep 11434
```

### ‚ùå Error: "No se puede conectar con JIRA"

**Soluciones:**
1. Verifica que las credenciales en `.env` sean correctas
2. Aseg√∫rate de que tu JIRA_SERVER tenga el formato: `https://company.atlassian.net`
3. Verifica que tu API token sea v√°lido
4. Comprueba que tengas permisos para leer tickets en el proyecto

### ‚ùå Error: "Model not found"

**Soluci√≥n:**
```bash
# Descargar el modelo nuevamente
ollama pull gemma:8b

# Verificar que se descarg√≥ correctamente
ollama list
```

### ‚ùå El clasificador tarda mucho

**Causas posibles:**
- Gemma 8B requiere recursos significativos
- Considera usar `gemma:2b` para menos RAM:
```bash
ollama pull gemma:2b
```
Luego edita `main.py` y cambia `model_name="gemma:2b"`

## üìä Rendimiento Esperado

- **Tiempo por ticket:** 3-10 segundos (dependiendo de hardware)
- **RAM necesaria:** 8-16GB para Gemma 8B
- **Precisi√≥n esperada:** 80-90% en clasificaciones

## üîí Consideraciones de Seguridad

- Los datos de JIRA se procesan localmente
- El modelo Gemma se ejecuta completamente offline
- Las credenciales se almacenan en archivo `.env` local
- **Importante:** No compartas tu archivo `.env` ni tu API token

## üìû Soporte

Si encuentras problemas:

1. Revisa esta gu√≠a de setup
2. Verifica los logs de Ollama
3. Aseg√∫rate de que las credenciales sean correctas
4. Comprueba que tengas suficiente RAM disponible

## üöÄ ¬°Listo para Comenzar!

Una vez completado el setup:

```bash
# 1. Crear tickets de prueba
python seeder.py

# 2. Clasificar tickets
python main.py

# 3. ¬°Disfruta de la clasificaci√≥n autom√°tica! üéâ
```